{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the brickcomps "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "AIS_Data = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP85/projections_antarctic_RCP85_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMSL_Data = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP85/projections_gmsl_RCP85_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LWS_Data = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP85/projections_landwater_storage_sl_RCP85_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_Data = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP85/projections_thermal_RCP85_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS_Data = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP85/projections_greenland_RCP85_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSIC_Data = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP85/projections_glaciers_RCP85_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct Brick components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim=10000\n",
    "GMSL=GMSL_Data[:,1:Sim];\n",
    "LWS=LWS_Data[:,1:Sim];\n",
    "GIS= GIS_Data[:,1:Sim];\n",
    "GSIC=GSIC_Data[:,1:Sim];\n",
    "TE=TE_Data[:,1:Sim];\n",
    "AIS=AIS_Data[:,1:Sim];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=collect(1850:2300);\n",
    "\n",
    "btime=Y;\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "brickcomps=Tuple([btime,AIS,GSIC,GIS,TE,LWS,GMSL]);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run Brick downscale function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_fingerprints (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_fingerprints()\n",
    "\n",
    "    fp_dir = joinpath(@__DIR__, \"..\", \"data\")\n",
    "    isdir(fp_dir) || mkpath(fp_dir)\n",
    "    fp_file = joinpath(fp_dir, \"FINGERPRINTS_SLANGEN_Bakker.nc\")\n",
    "    if !isfile(fp_file)\n",
    "        url = \"https://github.com/scrim-network/BRICK/raw/master/fingerprints/FINGERPRINTS_SLANGEN_Bakker.nc\"\n",
    "        download(url, fp_file)\n",
    "    end\n",
    "\n",
    "    fplat = ncread(fp_file,\"lat\")\n",
    "    fplon = ncread(fp_file,\"lon\")\n",
    "    fpAIS = ncread(fp_file,\"AIS\")\n",
    "    fpGSIC = ncread(fp_file,\"GLAC\")\n",
    "    fpGIS = ncread(fp_file,\"GIS\")\n",
    "    ncclose()\n",
    "\n",
    "    return fplat,fplon,fpAIS,fpGSIC,fpGIS\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subtractor (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function subtractor(minval,maxval)\n",
    "    function y(point,n)\n",
    "        if point - n < minval\n",
    "            return min(maxval,point - n + maxval)\n",
    "        else\n",
    "            return point - n\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adder (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function adder(maxval)\n",
    "    function y(point,n)\n",
    "        if point + n > maxval\n",
    "            return point + n - maxval\n",
    "        else\n",
    "            return point + n\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(::var\"#y#1\"{Int64, Int64}) (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lon_subtractor = subtractor(1,360)\n",
    "lon_adder = adder(360)\n",
    "lat_adder = adder(180)\n",
    "lat_subtractor = subtractor(1,180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "downscale_brick (generic function with 4 methods)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Statistics\n",
    "using NetCDF\n",
    "function downscale_brick(brickcomps, lonlat, ensInds, ystart=2010, yend=2100, tstep=10)\n",
    "    # To do - check with vectors of lat, lon\n",
    "    (fplat,fplon,fpAIS,fpGSIC,fpGIS) = get_fingerprints()\n",
    "    (btime,AIS,GSIC,GIS,TE,LWS,GMSL) = brickcomps\n",
    "\n",
    "    # Select indices of time of interest, with respect to timestep\n",
    "    tinds = findall(x -> x .>= ystart && x .<=yend, btime)\n",
    "    years = collect(ystart:yend)\n",
    "    yinds = findall(x -> x % tstep==0, years)\n",
    "    # Need to normalize LSL relative to 2000\n",
    "    inorm = findall(x -> x==2000, btime)\n",
    "\n",
    "    tdim=length(btime)\n",
    "\n",
    "    if length(years)==length(tinds)\n",
    "        tinds = tinds[yinds]\n",
    "    else\n",
    "        println(\"Error: years outside of bounds\")\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "    num_ens = length(ensInds)\n",
    "    \n",
    "    # Output matrix: ens x time x segment\n",
    "    lsl_out = zeros(num_ens, length(tinds), length(lonlat))\n",
    "\n",
    "    # Trim component vectors to timesteps and ensembles. Assume interval is 1 year\n",
    "    if tdim==size(AIS)[1] # check that time dimension is 1\n",
    "        # for normalizing\n",
    "        AIS_norm = AIS[inorm,ensInds]\n",
    "        GSIC_norm = GSIC[inorm,ensInds]\n",
    "        GIS_norm = GIS[inorm,ensInds]\n",
    "        TE_norm = TE[inorm,ensInds]\n",
    "        LWS_norm = LWS[inorm,ensInds]\n",
    "        GMSL_norm = GMSL[inorm,ensInds]\n",
    "        # actual projections\n",
    "        AIS = AIS[tinds,ensInds]\n",
    "        GSIC = GSIC[tinds,ensInds]\n",
    "        GIS = GIS[tinds,ensInds]\n",
    "        TE = TE[tinds,ensInds]\n",
    "        LWS = LWS[tinds,ensInds]\n",
    "        GMSL = GMSL[tinds,ensInds]\n",
    "    else\n",
    "        println(\"Error: time dimension is not 1 for brick components\")\n",
    "        return nothing\n",
    "    end\n",
    "\n",
    "  \n",
    "\n",
    "    for f in 1:length(lonlat) # Loop through lonlat tuples\n",
    "\n",
    "        lon = lonlat[f][1]\n",
    "        lat = lonlat[f][2]\n",
    "        # Convert Longitude to degrees East\n",
    "        # CIAM Lat is already in (-90,90) by default\n",
    "        if lon <0\n",
    "            lon = lon + 360\n",
    "        end\n",
    "\n",
    "        # Find fingerprint degrees nearest to lat,lon\n",
    "        ilat = findall(isequal(minimum(abs.(fplat.-lat))),abs.(fplat.-lat))\n",
    "        ilon = findall(isequal(minimum(abs.(fplon.-lon))),abs.(fplon.-lon))\n",
    "\n",
    "\n",
    "        # Take average of closest lat/lon values\n",
    "        fpAIS_flat = collect(skipmissing(Iterators.flatten(fpAIS[ilon,ilat])))\n",
    "        fpGSIC_flat = collect(skipmissing(Iterators.flatten(fpGSIC[ilon,ilat])))\n",
    "        fpGIS_flat = collect(skipmissing(Iterators.flatten(fpGIS[ilon,ilat])))\n",
    "\n",
    "        fpAIS_loc = mean(fpAIS_flat[isnan.(fpAIS_flat).==false],dims=1)[1]\n",
    "        fpGSIC_loc = mean(fpGSIC_flat[isnan.(fpGSIC_flat).==false],dims=1)[1]\n",
    "        fpGIS_loc = mean(fpGIS_flat[isnan.(fpGIS_flat).==false],dims=1)[1]\n",
    "        fpTE_loc = 1.0\n",
    "        fpLWS_loc=1.0\n",
    "\n",
    "        # Keep searching nearby lat/lon values if fingerprint value is NaN unless limit is hit\n",
    "        inc =1\n",
    "\n",
    "        while isnan(fpAIS_loc) || isnan(fpGIS_loc) || isnan(fpGSIC_loc) && inc<5\n",
    "\n",
    "            newlonStart = lon_subtractor.(fplon[ilon],inc)[1]\n",
    "            newlatStart = lat_subtractor.(fplat[ilat],inc)[1]\n",
    "            newlonEnd = lon_adder.(fplon[ilon],inc)[1]\n",
    "            newlatEnd = lat_adder.(fplat[ilat],inc)[1]\n",
    "\n",
    "            latInd1 = minimum(findall(isequal(minimum(abs.(fplat.-newlatStart))),abs.(fplat.-newlatStart)))\n",
    "            #minimum(findall(x-> x in newlatStart,fplat))\n",
    "            latInd2 = maximum(findall(isequal(minimum(abs.(fplat.-newlatEnd))),abs.(fplat.-newlatEnd)))\n",
    "            #maximum(findall(x -> x in newlatEnd,fplat))\n",
    "\n",
    "            lonInd1 = minimum(findall(isequal(minimum(abs.(fplon.-newlonStart))),abs.(fplon.-newlonStart)))\n",
    "            #minimum(findall(x-> x in newlonStart,fplon))\n",
    "            lonInd2 = maximum(findall(isequal(minimum(abs.(fplon.-newlonEnd))),abs.(fplon.-newlonEnd)))\n",
    "            #maximum(findall(x -> x in newlonEnd,fplon))\n",
    "\n",
    "            if latInd2 < latInd1\n",
    "                latInds=[latInd1; 1:latInd2]\n",
    "            else\n",
    "                latInds=latInd1:latInd2\n",
    "            end\n",
    "\n",
    "            if lonInd2 < lonInd1\n",
    "                lonInds=[lonInd1; 1:lonInd2]\n",
    "            else\n",
    "                lonInds = lonInd1:lonInd2\n",
    "            end\n",
    "\n",
    "            fpAIS_flat = collect(skipmissing(Iterators.flatten(fpAIS[lonInds,latInds])))\n",
    "            fpGSIC_flat = collect(skipmissing(Iterators.flatten(fpGSIC[lonInds,latInds])))\n",
    "            fpGIS_flat = collect(skipmissing(Iterators.flatten(fpGIS[lonInds,latInds])))\n",
    "\n",
    "            fpAIS_loc = mean(fpAIS_flat[isnan.(fpAIS_flat).==false],dims=1)[1]\n",
    "            fpGSIC_loc = mean(fpGSIC_flat[isnan.(fpGSIC_flat).==false],dims=1)[1]\n",
    "            fpGIS_loc = mean(fpGIS_flat[isnan.(fpGIS_flat).==false],dims=1)[1]\n",
    "\n",
    "            inc = inc + 1\n",
    "\n",
    "        end\n",
    "\n",
    "        # If still NaN, throw an error\n",
    "        if isnan(fpAIS_loc) || isnan(fpGIS_loc) || isnan(fpGSIC_loc)\n",
    "            println(\"Error: no fingerprints found for ($(lon),$(lat))\")\n",
    "            return nothing\n",
    "        end\n",
    "       # Multiply fingerprints by BRICK ensemble members\n",
    "       if ndims(AIS) > 1\n",
    "        for n in 1:size(AIS)[2] # loop through ensemble members\n",
    "            lsl_out[n, :, f] = fpGIS_loc * GIS[:,n] + fpAIS_loc * AIS[:,n] + fpGSIC_loc * GSIC[:,n] +\n",
    "                               fpTE_loc * TE[:,n] + fpLWS_loc * LWS[:,n]\n",
    "            # CIAM - LSL should be sea-level change relative to year 2000\n",
    "            lsl_norm = fpGIS_loc * GIS_norm[1,n] + fpAIS_loc * AIS_norm[1,n] + fpGSIC_loc * GSIC_norm[1,n] +\n",
    "                       fpTE_loc * TE_norm[1,n] + fpLWS_loc * LWS_norm[1,n]\n",
    "            lsl_out[n, :, f] = lsl_out[n, :, f] .- lsl_norm\n",
    "            \n",
    "        end\n",
    "    else\n",
    "            lsl_out[1, :, f] = fpGIS_loc * GIS[:] + fpAIS_loc * AIS[:] + fpGSIC_loc * GSIC[:] +\n",
    "                                fpTE_loc * TE[:] + fpLWS_loc * LWS[:]\n",
    "            # CIAM - LSL should be sea-level change relative to year 2000\n",
    "            lsl_norm = fpGIS_loc * GIS_norm + fpAIS_loc * AIS_norm + fpGSIC_loc * GSIC_norm +\n",
    "                                fpTE_loc * TE_norm + fpLWS_loc * LWS_norm\n",
    "            lsl_out[1, :, f] = lsl_out[1, :, f] .- lsl_norm\n",
    "    end\n",
    "\n",
    "    end # End lonlat tuple\n",
    "\n",
    "    return lsl_out,GMSL\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensInds=collect(1:10000);\n",
    "lonlat= ([-122.4194,37.7749],[153.0260,-27.4705],[12.3155,45.4408],[4.3007,52.0705],[43.6159,-23.1453]);\n",
    "ystart=2010;\n",
    "yend=2200;\n",
    "tstep=10;\n",
    "\n",
    "lslrNew85,H=downscale_brick(brickcomps, lonlat, ensInds, ystart, yend, tstep);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the Local SLR for Manzanillo, Colima and New Orleans in a CVS File \n",
    "1) Make a data frame for each one\n",
    "2) Save it as a CVS File"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCP 8.5 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random locations\n",
    "RandomL85=zeros(5,20,10001);\n",
    "#First colum are the years 2010 to 2200 with time step of 10 years\n",
    "for k in 1:5\n",
    "    for i in 1:20\n",
    "        RandomL85[k,i,1]=2000+i*10\n",
    "    end\n",
    "#SLR value for each year for each simulation \n",
    "    for i in 1:10000\n",
    "        for j in 1:20\n",
    "            RandomL85[k,j,i+1]=lslrNew85[i,j,k]\n",
    "     end \n",
    "    end \n",
    "end\n",
    "\n",
    "projections_Random_LSLR_RCP85_R=reshape(RandomL85,100,10001)\n",
    "\n",
    "using CSV\n",
    "using Tables\n",
    "CSV.write(\"projections_Random_LSLR_RCP85.csv\", Tables.table(projections_Random_LSLR_RCP85_R))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100×10001 Matrix{Float64}:\n",
       " 2010.0  0.0236679  0.0228118  0.0313817  …  0.0277411  0.0299613  0.0282152\n",
       " 2010.0  0.0281391  0.0243799  0.0376155     0.0330962  0.0323219  0.0309098\n",
       " 2010.0  0.0230695  0.0213039  0.0313428     0.0269861  0.0281754  0.0266406\n",
       " 2010.0  0.0217139  0.0201942  0.0302372     0.0255152  0.0269656  0.0254127\n",
       " 2010.0  0.0282792  0.0246069  0.0375669     0.0332108  0.0325208  0.0310984\n",
       " 2020.0  0.0588795  0.0557887  0.0663297  …  0.0599051  0.0649833  0.0623116\n",
       " 2020.0  0.0718151  0.0656509  0.0787114     0.0690885  0.0740213  0.0721736\n",
       " 2020.0  0.057702   0.053553   0.0649355     0.0566187  0.061881   0.0595175\n",
       " 2020.0  0.0542664  0.0502594  0.0619169     0.0530837  0.0585722  0.0561419\n",
       " 2020.0  0.0720709  0.0660362  0.0788563     0.0695712  0.0744422  0.0725703\n",
       " 2030.0  0.1019     0.0917212  0.109307   …  0.1031     0.112156   0.10906\n",
       " 2030.0  0.122903   0.109221   0.129123      0.120521   0.131768   0.129949\n",
       " 2030.0  0.0971884  0.0874827  0.104962      0.0961883  0.106535   0.102939\n",
       "    ⋮                                     ⋱                        ⋮\n",
       " 2180.0  3.41341    2.11171    3.56258       2.75685    2.37814    3.07946\n",
       " 2180.0  6.07913    3.45402    5.82537       5.33224    5.03827    6.25575\n",
       " 2190.0  5.79521    3.3604     5.78583    …  5.01199    4.65932    5.84566\n",
       " 2190.0  6.41912    3.69047    6.25061       5.61615    5.33141    6.5986\n",
       " 2190.0  4.47667    2.70087    4.58472       3.76743    3.42352    4.32104\n",
       " 2190.0  3.65998    2.29868    3.89542       2.9703     2.58218    3.32642\n",
       " 2190.0  6.61606    3.78559    6.41842       5.80996    5.53593    6.84132\n",
       " 2200.0  6.25252    3.65292    6.32121    …  5.40886    5.07882    6.32235\n",
       " 2200.0  6.92884    4.00615    6.822         6.0612     5.80408    7.13403\n",
       " 2200.0  4.80384    2.92428    4.99172       4.04866    3.71464    4.65211\n",
       " 2200.0  3.90512    2.48204    4.23045       3.1776     2.78965    3.56368\n",
       " 2200.0  7.14633    4.11131    7.0081        6.27351    6.0297     7.40043"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projections_Random_LSLR_RCP85_R=reshape(RandomL85,100,10001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mcurl_easy_setopt: 48\n",
      "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Downloads.Curl /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Downloads/src/Curl/utils.jl:36\u001b[39m\n",
      "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mcurl_easy_setopt: 48\n",
      "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Downloads.Curl /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Downloads/src/Curl/utils.jl:36\u001b[39m\n",
      "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mcurl_easy_setopt: 48\n",
      "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ Downloads.Curl /Users/julia/buildbot/worker/package_macos64/build/usr/share/julia/stdlib/v1.6/Downloads/src/Curl/utils.jl:36\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "import Pkg \n",
    "Pkg.add(\"Tables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"projections_Random_LSLR_RCP85.csv\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV\n",
    "using Tables\n",
    "CSV.write(\"projections_Random_LSLR_RCP85.csv\", Tables.table(projections_Random_LSLR_RCP85_R))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCP 6.0 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "using CSV\n",
    "AIS_Data60 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP60/projections_antarctic_RCP60_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMSL_Data60 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP60/projections_gmsl_RCP60_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "LWS_Data60 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP60/projections_landwater_storage_sl_RCP60_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_Data60 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP60/projections_thermal_RCP60_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS_Data60 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP60/projections_greenland_RCP60_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSIC_Data60 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP60/projections_glaciers_RCP60_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim=10000\n",
    "GMSL60=GMSL_Data60[:,1:Sim];\n",
    "LWS60=LWS_Data60[:,1:Sim];\n",
    "GIS60= GIS_Data60[:,1:Sim];\n",
    "GSIC60=GSIC_Data60[:,1:Sim];\n",
    "TE60=TE_Data60[:,1:Sim];\n",
    "AIS60=AIS_Data60[:,1:Sim];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "brickcomps60=Tuple([btime,AIS60,GSIC60,GIS60,TE60,LWS60,GMSL60]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensInds=collect(1:10000);\n",
    "lonlat= ([-122.4194,37.7749],[153.0260,-27.4705],[12.3155,45.4408],[4.3007,52.0705],[43.6159,-23.1453]);\n",
    "ystart=2010;\n",
    "yend=2200;\n",
    "tstep=10;\n",
    "\n",
    "lslrNew60,H60=downscale_brick(brickcomps60, lonlat, ensInds, ystart, yend, tstep);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"projections_Random_LSLR_RCP60.csv\""
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random locations\n",
    "RandomL60=zeros(5,20,10001);\n",
    "#First colum are the years 2010 to 2200 with time step of 10 years\n",
    "for k in 1:5\n",
    "    for i in 1:20\n",
    "        RandomL60[k,i,1]=2000+i*10\n",
    "    end\n",
    "#SLR value for each year for each simulation \n",
    "    for i in 1:10000\n",
    "        for j in 1:20\n",
    "            RandomL60[k,j,i+1]=lslrNew60[i,j,k]\n",
    "     end \n",
    "    end \n",
    "end\n",
    "\n",
    "projections_Random_LSLR_RCP60_R=reshape(RandomL60,100,10001)\n",
    "\n",
    "using CSV\n",
    "using Tables\n",
    "CSV.write(\"projections_Random_LSLR_RCP60.csv\", Tables.table(projections_Random_LSLR_RCP60_R))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCP 4.5 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIS_Data45 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP45/projections_antarctic_RCP45_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMSL_Data45= CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP45/projections_gmsl_RCP45_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "LWS_Data45 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP45/projections_landwater_storage_sl_RCP45_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_Data45 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP45/projections_thermal_RCP45_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS_Data45 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP45/projections_greenland_RCP45_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSIC_Data45 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP45/projections_glaciers_RCP45_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim=10000\n",
    "GMSL45=GMSL_Data45[:,1:Sim];\n",
    "LWS45=LWS_Data45[:,1:Sim];\n",
    "GIS45= GIS_Data45[:,1:Sim];\n",
    "GSIC45=GSIC_Data45[:,1:Sim];\n",
    "TE45=TE_Data45[:,1:Sim];\n",
    "AIS45=AIS_Data45[:,1:Sim];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "brickcomps45=Tuple([btime,AIS45,GSIC45,GIS45,TE45,LWS45,GMSL45]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensInds=collect(1:10000);\n",
    "lonlat= ([-122.4194,37.7749],[153.0260,-27.4705],[12.3155,45.4408],[4.3007,52.0705],[43.6159,-23.1453]);\n",
    "ystart=2010;\n",
    "yend=2200;\n",
    "tstep=10;\n",
    "\n",
    "lslrNew45,H=downscale_brick(brickcomps45, lonlat, ensInds, ystart, yend, tstep);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"projections_Random_LSLR_RCP45.csv\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random locations\n",
    "RandomL45=zeros(5,20,10001);\n",
    "#First colum are the years 2010 to 2200 with time step of 10 years\n",
    "for k in 1:5\n",
    "    for i in 1:20\n",
    "        RandomL45[k,i,1]=2000+i*10\n",
    "    end\n",
    "#SLR value for each year for each simulation \n",
    "    for i in 1:10000\n",
    "        for j in 1:20\n",
    "            RandomL45[k,j,i+1]=lslrNew45[i,j,k]\n",
    "     end \n",
    "    end \n",
    "end\n",
    "\n",
    "projections_Random_LSLR_RCP45_R=reshape(RandomL45,100,10001)\n",
    "\n",
    "using CSV\n",
    "using Tables\n",
    "CSV.write(\"projections_Random_LSLR_RCP45.csv\", Tables.table(projections_Random_LSLR_RCP45_R))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RCP 2.6 case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "AIS_Data26 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP26/projections_antarctic_RCP26_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "GMSL_Data26 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP26/projections_gmsl_RCP26_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LWS_Data26 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP26/projections_landwater_storage_sl_RCP26_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "TE_Data26 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP26/projections_thermal_RCP26_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "GIS_Data26 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP26/projections_greenland_RCP26_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "GSIC_Data26 = CSV.File(\"/Users/ce3304/Downloads/projections_csv/RCP26/projections_glaciers_RCP26_sneasybrick.csv\") |> DataFrame;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sim=10000\n",
    "GMSL26=GMSL_Data26[:,1:Sim];\n",
    "LWS26=LWS_Data26[:,1:Sim];\n",
    "GIS26= GIS_Data26[:,1:Sim];\n",
    "GSIC26=GSIC_Data26[:,1:Sim];\n",
    "TE26=TE_Data26[:,1:Sim];\n",
    "AIS26=AIS_Data26[:,1:Sim];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "brickcomps26=Tuple([btime,AIS26,GSIC26,GIS26,TE26,LWS26,GMSL26]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensInds=collect(1:10000);\n",
    "lonlat= ([-122.4194,37.7749],[153.0260,-27.4705],[12.3155,45.4408],[4.3007,52.0705],[43.6159,-23.1453]);\n",
    "ystart=2010;\n",
    "yend=2200;\n",
    "tstep=10;\n",
    "\n",
    "lslrNew26,H=downscale_brick(brickcomps26, lonlat, ensInds, ystart, yend, tstep);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"projections_Random_LSLR_RCP26.csv\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random locations\n",
    "RandomL26=zeros(5,20,10001);\n",
    "#First colum are the years 2010 to 2200 with time step of 10 years\n",
    "for k in 1:5\n",
    "    for i in 1:20\n",
    "        RandomL26[k,i,1]=2000+i*10\n",
    "    end\n",
    "#SLR value for each year for each simulation \n",
    "    for i in 1:10000\n",
    "        for j in 1:20\n",
    "            RandomL26[k,j,i+1]=lslrNew26[i,j,k]\n",
    "     end \n",
    "    end \n",
    "end\n",
    "\n",
    "projections_Random_LSLR_RCP26_R=reshape(RandomL26,100,10001)\n",
    "\n",
    "using CSV\n",
    "using Tables\n",
    "CSV.write(\"projections_Random_LSLR_RCP26.csv\", Tables.table(projections_Random_LSLR_RCP26_R))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
